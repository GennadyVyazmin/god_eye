import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.optimize import linear_sum_assignment
from typing import List, Tuple
import cv2
import scipy.linalg


class KalmanFilter:
    def __init__(self):
        self._motion_mat = np.eye(8, 8)
        for i in range(4):
            self._motion_mat[i, i + 4] = 1
        self._update_mat = np.eye(4, 8)
        self._std_weight_position = 1. / 20
        self._std_weight_velocity = 1. / 160

    def initiate(self, measurement: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        mean = np.r_[measurement, np.zeros_like(measurement)]
        std = [
            2 * self._std_weight_position * measurement[3],
            2 * self._std_weight_position * measurement[3],
            1e-2,
            2 * self._std_weight_position * measurement[3],
            10 * self._std_weight_velocity * measurement[3],
            10 * self._std_weight_velocity * measurement[3],
            1e-5,
            10 * self._std_weight_velocity * measurement[3]]
        covariance = np.diag(np.square(std))
        return mean, covariance

    def predict(self, mean: np.ndarray, covariance: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        std_pos = [
            self._std_weight_position * mean[3],
            self._std_weight_position * mean[3],
            1e-2,
            self._std_weight_position * mean[3]]
        std_vel = [
            self._std_weight_velocity * mean[3],
            self._std_weight_velocity * mean[3],
            1e-5,
            self._std_weight_velocity * mean[3]]
        motion_cov = np.diag(np.square(np.r_[std_pos, std_vel]))
        mean = np.dot(self._motion_mat, mean)
        covariance = np.linalg.multi_dot((self._motion_mat, covariance, self._motion_mat.T)) + motion_cov
        return mean, covariance

    def project(self, mean: np.ndarray, covariance: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        std = [
            self._std_weight_position * mean[3],
            self._std_weight_position * mean[3],
            1e-1,
            self._std_weight_position * mean[3]]
        innovation_cov = np.diag(np.square(std))
        mean = np.dot(self._update_mat, mean)
        covariance = np.linalg.multi_dot((self._update_mat, covariance, self._update_mat.T))
        return mean, covariance + innovation_cov

    def update(self, mean: np.ndarray, covariance: np.ndarray, measurement: np.ndarray) -> Tuple[
        np.ndarray, np.ndarray]:
        projected_mean, projected_cov = self.project(mean, covariance)
        chol_factor, lower = scipy.linalg.cho_factor(projected_cov, lower=True, check_finite=False)
        kalman_gain = scipy.linalg.cho_solve((chol_factor, lower),
                                             np.dot(covariance, self._update_mat.T).T,
                                             check_finite=False).T
        innovation = measurement - projected_mean
        new_mean = mean + np.dot(innovation, kalman_gain.T)
        new_covariance = covariance - np.linalg.multi_dot((kalman_gain, projected_cov, kalman_gain.T))
        return new_mean, new_covariance


class Track:
    def __init__(self, mean, covariance, track_id, n_init, max_age, feature=None):
        self.mean = mean
        self.covariance = covariance
        self.track_id = track_id
        self.hits = 1
        self.age = 1
        self.time_since_update = 0
        self.state = 'tentative' if n_init > 0 else 'confirmed'
        self.features = []
        if feature is not None:
            self.features.append(feature)
        self._n_init = n_init
        self._max_age = max_age

    def predict(self, kf):
        self.mean, self.covariance = kf.predict(self.mean, self.covariance)
        self.age += 1
        self.time_since_update += 1

    def update(self, kf, detection):
        self.mean, self.covariance = kf.update(self.mean, self.covariance, detection.to_xyah())
        self.features.append(detection.feature)
        self.hits += 1
        self.time_since_update = 0
        if self.state == 'tentative' and self.hits >= self._n_init:
            self.state = 'confirmed'

    def mark_missed(self):
        if self.state == 'tentative':
            self.state = 'deleted'
        elif self.time_since_update > self._max_age:
            self.state = 'deleted'

    def is_tentative(self):
        return self.state == 'tentative'

    def is_confirmed(self):
        return self.state == 'confirmed'

    def is_deleted(self):
        return self.state == 'deleted'

    def __repr__(self):
        return f"Track(id={self.track_id}, state={self.state}, hits={self.hits}, age={self.age})"


class Detection:
    def __init__(self, tlwh, confidence, feature):
        self.tlwh = np.asarray(tlwh, dtype=np.float64)
        self.confidence = float(confidence)
        self.feature = np.asarray(feature, dtype=np.float32)

    def to_tlbr(self):
        ret = self.tlwh.copy()
        ret[2:] += ret[:2]
        return ret

    def to_xyah(self):
        ret = self.tlwh.copy()
        ret[:2] += ret[2:] / 2
        ret[2] /= ret[3]
        return ret


class NearestNeighborDistanceMetric:
    def __init__(self, metric, matching_threshold, budget=None):
        if metric == "cosine":
            self._metric = self._cosine_distance
        elif metric == "euclidean":
            self._metric = self._euclidean_distance
        else:
            raise ValueError("Invalid metric; must be either 'euclidean' or 'cosine'")
        self.matching_threshold = matching_threshold
        self.budget = budget
        self.samples = {}

    def _cosine_distance(self, x, y):
        """–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ"""
        x = np.asarray(x, dtype=np.float32)
        y = np.asarray(y, dtype=np.float32)

        if x.ndim == 1:
            x = x.reshape(1, -1)
        if y.ndim == 1:
            y = y.reshape(1, -1)

        x_norm = np.linalg.norm(x, axis=1, keepdims=True)
        y_norm = np.linalg.norm(y, axis=1, keepdims=True)

        x_norm[x_norm == 0] = 1e-10
        y_norm[y_norm == 0] = 1e-10

        x_normalized = x / x_norm
        y_normalized = y / y_norm

        cosine_similarity = np.dot(x_normalized, y_normalized.T)
        cosine_distance = 1.0 - cosine_similarity
        cosine_distance = np.clip(cosine_distance, 0.0, 2.0)

        if cosine_distance.shape == (1, 1):
            return cosine_distance[0, 0]

        return cosine_distance

    def _euclidean_distance(self, x, y):
        """–ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–ø—Ä–æ—â–µ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –¥–ª—è –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ñ–∏—á)"""
        x = np.asarray(x, dtype=np.float32)
        y = np.asarray(y, dtype=np.float32)

        if x.ndim == 1:
            x = x.reshape(1, -1)
        if y.ndim == 1:
            y = y.reshape(1, -1)

        # –ï–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
        dist = np.sqrt(np.sum((x - y) ** 2, axis=1))

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º (–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ ~ sqrt(2))
        dist = dist / np.sqrt(2.0)

        return dist[0] if dist.shape == (1,) else dist

    def partial_fit(self, features, targets, active_targets):
        for feature, target in zip(features, targets):
            self.samples.setdefault(target, []).append(feature)
            if self.budget is not None:
                self.samples[target] = self.samples[target][-self.budget:]
        self.samples = {k: self.samples[k] for k in active_targets}

    def distance(self, features, targets):
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        """
        if len(features) == 0 or len(targets) == 0:
            return np.zeros((len(features), len(targets)), dtype=np.float32)

        cost_matrix = np.zeros((len(features), len(targets)), dtype=np.float32)

        for i, feature in enumerate(features):
            for j, target in enumerate(targets):
                if target in self.samples and len(self.samples[target]) > 0:
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ñ–∏—á—É —Ç—Ä–µ–∫–∞
                    target_feature = self.samples[target][-1]
                    dist = self._metric(feature, target_feature)
                    cost_matrix[i, j] = dist
                    # –î–ï–ë–ê–ì: –ª–æ–≥–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                    if dist < 0.3:  # –¢–æ–ª—å–∫–æ –±–ª–∏–∑–∫–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
                        print(f"      Distance Detection {i} -> Track {target}: {dist:.3f}")
                else:
                    cost_matrix[i, j] = 1.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è

        return cost_matrix


class Tracker:
    def __init__(self, metric, max_iou_distance=0.7, max_age=70, n_init=3):
        self.metric = metric
        self.max_iou_distance = max_iou_distance
        self.max_age = max_age
        self.n_init = n_init
        self.kf = KalmanFilter()
        self.tracks = []
        self._next_id = 1

    def predict(self):
        for track in self.tracks:
            track.predict(self.kf)

    def update(self, detections):
        """Perform measurement update and track management."""
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if detections is None:
                detections = []

            # Run matching cascade.
            matches, unmatched_tracks, unmatched_detections = self._match(detections)

            # Update track set.
            for track_idx, detection_idx in matches:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–æ–≤
                if (0 <= track_idx < len(self.tracks) and
                        0 <= detection_idx < len(detections)):
                    self.tracks[track_idx].update(self.kf, detections[detection_idx])
                else:
                    print(f"Invalid match indices: track_idx={track_idx}, detection_idx={detection_idx}")

            for track_idx in unmatched_tracks:
                if 0 <= track_idx < len(self.tracks):
                    self.tracks[track_idx].mark_missed()
                else:
                    print(f"Invalid unmatched track index: {track_idx}")

            for detection_idx in unmatched_detections:
                if 0 <= detection_idx < len(detections):
                    self._initiate_track(detections[detection_idx])
                else:
                    print(f"Invalid unmatched detection index: {detection_idx}")

            # Remove deleted tracks.
            self.tracks = [t for t in self.tracks if not t.is_deleted()]

        except Exception as e:
            print(f"Error in tracker update: {e}")
            import traceback
            traceback.print_exc()
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Ç—Ä–µ–∫–∏
            self.tracks = [t for t in self.tracks if not t.is_deleted()]

    def _match(self, detections):
        if len(detections) == 0:
            return [], [], []

        if len(self.tracks) == 0:
            return [], [], list(range(len(detections)))

        # –†–∞–∑–¥–µ–ª—è–µ–º —Ç—Ä–µ–∫–∏ –Ω–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ –∏ –Ω–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ
        confirmed_tracks = []
        unconfirmed_tracks = []

        for i, t in enumerate(self.tracks):
            if t.is_confirmed():
                confirmed_tracks.append(i)
            else:
                unconfirmed_tracks.append(i)

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏
        matches_a, unmatched_tracks_a, unmatched_detections = self._linear_assignment(
            confirmed_tracks, detections)

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –Ω–µ–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏
        matches_b, unmatched_tracks_b, unmatched_detections = self._linear_assignment(
            unconfirmed_tracks, detections, unmatched_detections)

        matches = matches_a + matches_b
        unmatched_tracks = unmatched_tracks_a + unmatched_tracks_b

        return matches, unmatched_tracks, unmatched_detections

    def _linear_assignment(self, track_indices, detections, unmatched_detections=None):
        if unmatched_detections is None:
            unmatched_detections = list(range(len(detections)))

        if len(track_indices) == 0 or len(unmatched_detections) == 0:
            return [], track_indices, unmatched_detections

        features = [detections[i].feature for i in unmatched_detections]
        targets = [self.tracks[i].track_id for i in track_indices]

        cost_matrix = self.metric.distance(features, targets)

        # –î–ï–ë–ê–ì: –≤—ã–≤–æ–¥–∏–º –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        print(f"  Matching {len(features)} detections with {len(targets)} tracks")
        print(f"  Cost matrix shape: {cost_matrix.shape}")
        if cost_matrix.size > 0:
            min_cost = np.min(cost_matrix)
            max_cost = np.max(cost_matrix)
            avg_cost = np.mean(cost_matrix)
            print(f"  Min cost: {min_cost:.3f}, Max cost: {max_cost:.3f}, Avg cost: {avg_cost:.3f}")
            print(f"  Matching threshold: {self.metric.matching_threshold}")

            # –í—ã–≤–æ–¥–∏–º –≤—Å—é –º–∞—Ç—Ä–∏—Ü—É
            print(f"  Cost matrix:")
            for i in range(cost_matrix.shape[0]):
                row_str = "    "
                for j in range(cost_matrix.shape[1]):
                    row_str += f"{cost_matrix[i, j]:.3f} "
                print(row_str)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –±–æ–ª—å—à–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞
        cost_matrix[cost_matrix > self.metric.matching_threshold] = 1e+5

        matches, unmatched_tracks, unmatched_detections_new = [], [], []

        try:
            if cost_matrix.size > 0 and cost_matrix.shape[0] > 0 and cost_matrix.shape[1] > 0:
                row_indices, col_indices = linear_sum_assignment(cost_matrix)

                # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
                matched_rows = set(row_indices)
                matched_cols = set(col_indices)

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                for row, col in zip(row_indices, col_indices):
                    track_idx = track_indices[row]
                    detection_idx = unmatched_detections[col]

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω–¥–µ–∫—Å—ã –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
                    if (row < len(track_indices) and col < len(unmatched_detections) and
                            track_idx < len(self.tracks) and detection_idx < len(detections)):

                        if cost_matrix[row, col] <= self.metric.matching_threshold:
                            matches.append((track_idx, detection_idx))
                            print(
                                f"    ‚úÖ MATCHED: Track {self.tracks[track_idx].track_id} -> Detection {detection_idx} (cost: {cost_matrix[row, col]:.3f})")
                        else:
                            unmatched_tracks.append(track_idx)
                            unmatched_detections_new.append(detection_idx)
                            print(
                                f"    ‚ùå NO MATCH: Track {self.tracks[track_idx].track_id} -> Detection {detection_idx} (cost: {cost_matrix[row, col]:.3f} > threshold: {self.metric.matching_threshold})")
                    else:
                        print(f"Invalid indices: track_idx={track_idx}, detection_idx={detection_idx}")

                # –ù–µ—Å–æ–≤–ø–∞–≤—à–∏–µ —Ç—Ä–µ–∫–∏
                for i, track_idx in enumerate(track_indices):
                    if i not in matched_rows:
                        unmatched_tracks.append(track_idx)

                # –ù–µ—Å–æ–≤–ø–∞–≤—à–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
                for j, detection_idx in enumerate(unmatched_detections):
                    if j not in matched_cols:
                        unmatched_detections_new.append(detection_idx)

        except Exception as e:
            print(f"Error in linear assignment: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –∫–∞–∫ –Ω–µ—Å–æ–≤–ø–∞–≤—à–∏–µ
            unmatched_tracks = track_indices.copy()
            unmatched_detections_new = unmatched_detections.copy()

        return matches, unmatched_tracks, unmatched_detections_new

    def _initiate_track(self, detection):
        mean, covariance = self.kf.initiate(detection.to_xyah())
        self.tracks.append(Track(
            mean, covariance, self._next_id, self.n_init, self.max_age,
            detection.feature))
        print(f"    üÜï NEW TRACK INITIATED: id={self._next_id}")
        self._next_id += 1